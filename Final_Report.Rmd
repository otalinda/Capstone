---
title: 'HarvardX Data Science Final Project: A Classification Task Using Machine Learning
  Techniques'
author: "Gretta Digbeu"
date: "July 28th, 2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE,results = 'hide'}

library(plyr)
library(tidyverse)
library(caret)
library(randomForest)
library(ggplot2)
library(viridis)
library(ggthemes)
library(ggrepel)
library(stringr)
library(reshape)
library(rockchalk)
library(RColorBrewer)
library(kableExtra)
library(tinytex)
library(reticulate)
library(scales)
library(gridExtra)
library(cowplot)
library(gtable)
library(tinytex)


options(tinytex.verbose = TRUE)

```

## __A.Introduction__

This machine learning exercise is the final component in the capstone course of the Harvard edX Data Science online professional certificate program. Students pursuing the verified track are asked to apply predictive machine learning techniques using a publicly available dataset to solve a problem of their choice. 

We chose to explore the 1996 _Adult_ dataset, also known as the _Census Income_ dataset, available on the  UCI's Machine Learning Repository. The data was extracted by Silicon Valley researchers (Ronny Kohavi and Barry Becker) from the 1994 Current Population Survey (CPS) data held in the Census database. It is already partitioned into training and testing sets containing 32,561 and 16,281 observations respectively (30,162 and 15,060 after removing unknowns), and includes 14 attributes. The variable of interest, gross income, was discretized into two ranges with a threshold of $50,000. The data is therefore ideal for a multivariate classification exercise with the goal of predicting this binary outcome variable.  

Before exploring the data for trends and patterns, let us present a breakdown of the attributes contained therein:

```{r, echo=FALSE}

attributes <- data.frame(
    attribute = c("age", "workclass", "final_weight", "education_level", "education_num", "marital_status", "occupation", "relationship", "race", "sex", "capital_gain", "capital_loss","hours_per_week","native_country", "income_category"),
    type = c("continuous", "categorical", "continuous", "categorical", "continuous", "categorical", "categorical", "categorical", "categorical", "binary", "continuous", "continuous", "continuous", "categorical", "categorical"),
    description = c("Age in years", "Class of worker", "Demographic weight", "Highest level of education achieved", "Total years of education", "Marital status", "Type of occupation", "Relationship of survey responder to the head of household", "Ethnic origin", "Biological sex", "Profits made from the sale of real estate, investments and personal property", "Losses incurred when capital assets decrease in value", "Average number of hours worked per week", "Country of origin", "Income in relation to 50k"))
```

```{r, echo = FALSE}
attributes %>%
  kable(caption = "Features and Their Types") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We note that there are 14 attributes, 6 of which are continuous and 8 are categorical. This includes the _weight_ feature assigned to each observation by the researchers at the Population Division of the Census Bureau. These weights are controlled to independent estimates of the civilian non-institutional population of the US, using 3 sets of controls: a single cell estimate of the population 16+ for each state; controls for Hispanic Origin by age and sex; and controls by Race, age and sex. People with similar demographic characteristics should therefore have similar weights, with one important caveat: because the CPS sample is a collection of 51 separate state samples, each with its own probability of selection, such similarities only apply to observations from the same state.

```{r, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE,results = 'hide'}

#1)Import
raw_training <- read.table("/Users/grettadigbeu/Desktop/R Files/adult.data", header=FALSE, sep=",", na.strings = "?", strip.white=TRUE)

#2) Assign column names
colnames(raw_training) <- c("age", 
                            "workclass", 
                            "final_weight", 
                            "education_level", 
                            "education_num", 
                            "marital_status", 
                            "occupation", 
                            "relationship", 
                            "race", 
                            "sex", "capital_gain", 
                            "capital_loss", 
                            "hours_per_week", 
                            "native_country", 
                            "income_category")

#3) Remove NAs

training <-na.omit(raw_training)

head(training)
str(training)

#VALIDATION SET#
################

#1)Import
raw_test <- read.table("/Users/grettadigbeu/Desktop/R Files/adult.test", skip = 1, header=FALSE, sep=",", na.strings = "?", strip.white=TRUE)
head(raw_test)

#2)Assign column names
colnames(raw_test) <- c("age", 
                       "workclass", 
                       "final_weight", 
                       "education_level", 
                       "education_num", 
                       "marital_status", 
                       "occupation", 
                       "relationship", 
                       "race", 
                       "sex", 
                       "capital_gain", 
                       "capital_loss", 
                       "hours_per_week", 
                       "native_country", 
                       "income_category")

#3) Remove NAs
testing <- na.omit(raw_test)
str(testing)

length(is.na(testing))

options(tinytex.verbose = TRUE)
```


## __B.Exploratory Data Analysis__

In order to identify trends and patterns in the census data, we must conduct some exploratory data analysis. Our findings will guide the methods employed in this exercise, and help us determine whether any transformations must be made to the data. These include but are not limited to: removing attributes highly correlated with other features, applying log transformations or scaling/standardizing the values of continuous attributes, and removing attributes with very few unique values or close to zero variation in our outcome variable. 

```{r, echo = FALSE, message=FALSE, error=FALSE, warning=FALSE}
devtools::source_gist('4a0a5ab9fe7e1cf3be0e')
str1 <- strtable(training)
str2 <- strtable(testing)
```

### __I.Data at a Glance__ 

After importing the training and testing sets separately and removing the unknowns, we assign the column names listed above. Note that for ease of understanding, these variable names differ slightly from the column names listed on the UCI Machine Learning Repository. Next, we examine the structure of each subset to ensure that they are structurally identical because we want to explore these trends over the entire sample, as opposed to examining the training and testing sets separately. The results are as follows:


```{r, echo = FALSE }
str1[,-4] %>% kable(caption = "Training Set") %>% kable_styling(bootstrap_options = c("striped", "hover"))

str2[,-4] %>% kable(caption = "Testing Set") %>% kable_styling(bootstrap_options = c("striped", "hover"))
```


Looking at the structure of each subset reveals that the levels of our variable of interest (income_category), are syntactically different. The levels in the testing set have an unnecessary period at the end of each expression. 


We therefore recode the levels in the testing data so they match the training set:

```{r}
levels(testing$income_category)[1] <- "<=50K"
levels(testing$income_category)[2] <- ">50K"
```


Moreover, a quick look at the relationship between the __education_level__ and __education_num__ variables reveals that the latter does not correspond to the total number of years of education. Rather, it is simply a numeric representation of the __education_level__ attribute:


```{r, echo = FALSE, message = FALSE}
t1 <- training %>% distinct(education_level, education_num) %>% arrange(education_num)
t2 <- testing %>% distinct(education_level, education_num) %>% arrange(education_num)
```

```{r, echo = FALSE}
t1 %>% kable(caption = "Relationship between education_level and education_num features: Training Set") %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

```{r, echo = FALSE}
t2 %>% kable(caption = "Relationship between education_level and education_num features: Training Set") %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

We can therefore remove the __education_num__ feature, as it is a redundant variable that provides no additional information about our population.  We remove it from both the testing and training data frames.

```{r, echo = FALSE}
training <- training %>% select(-education_num)
testing <- testing %>% select(-education_num)
```

We can now proceed to bind the rows and explore the full dataset. Excluding the unknowns, our census sample has __45,222__ observations. 

```{r, echo=FALSE}
#Bind rows to combine testing and training data
data_all <- rbind(training, testing)
str(data_all)
```

First, we look at the prevalence of each class of our outcome variable. What is relative proportion of people making more than $50,000 a year in our sample?

```{r, echo=FALSE}
share <- data_all %>%
  group_by(income_category) %>%
  tally() %>%
  mutate(pct = n / sum(n), percentage = paste0(round(pct*100, 1), "%"))

share %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

We note that at 75.4%, the prevalence of people with incomes below or equal to $50,000/year is much higher than that of people making more than $50,000/year. The implication of the uneven prevalence is that when it comes time to assessing our algorithm, it will be more useful to look at a precision/recall curve as opposed to a ROC curve. This curve plots the true positive rate (sensitivity) against specificity, so that we can gauge how for each class of our income variable(<= 50K and >50K), the probability of a __true positive__ given a __predicted positive__ changes in relation to the true positive rate. The high prevalence of people with incomes equal to or below the $50,000 threshold also means that: instead of taking the balanced accuracy (F1 score) generated from the confusion matrix at face value, we should compute a weighted score using the f_meas() function, adjusting the _Beta_ accordingly. 

### __II.Deep Dive__ 

#### __II.1 Categorical Attributes__

We now proceed to take a deeper dive into a selection of features one by one, starting with the categorical variables. These are __workclass, education_level, marital_status, occupation, relationship, race, sex, and native_country__. These are all factor variables so we take a look at the levels contained in each. 

We notice that the variable __work_class__ (class of worker) has an unused level ("never-worked"), so we drop it from the data.  

```{r}
summary(data_all$workclass)

#Remove unused level "never_worked" 
  data_all$workclass <- droplevels(data_all$workclass)

```

Upon summarizing the data along this feature, we note that most survey respondents (73.7%) are private sector workers, and that the highest concentration of individuals earning more than 50K/year is found among the incorporated self-employed workers (self-emp-inc).

```{r, echo=FALSE} 
  #Make the bar graph of frequencies 
  proportion0 <- data_all %>%
    group_by(workclass) %>%
    tally() %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  

  p0 <- proportion0 %>% 
    ggplot(aes(x = reorder(workclass, -pct), y = pct)) +
    geom_bar(stat = "identity", position = "dodge", fill = "lightgoldenrod1", color = "black", alpha=.9) +
    geom_text(aes(label = y_label), position = position_dodge(width=.9), vjust = -.25) +
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    xlab("")+
    ylab("")+
    theme_clean()+
    ggtitle("Types of Employment") 
    

  #Make stacked bars
  proportion1 <- data_all %>%
    group_by(workclass, income_category) %>%
    tally() %>%
    group_by(workclass) %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p1<- proportion1 %>% 
    ggplot(aes(y = pct, x = workclass, fill = income_category))+
    geom_bar(position = "fill", stat = "identity", alpha = .8) +
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    geom_text(aes(label = y_label), position = position_stack(vjust = .5), color = "black") +
    xlab("")+
    ylab("")+
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    ggtitle("Breakdown of Income Class by Class of Worker") + 
    theme_clean()
    
```

```{r fig.width=10, fig.height=8, fig.align="left", echo = FALSE}
grid.arrange(p0,p1, nrow=2)
```

Next, we look at the __education_level__ variable. We see that there is an unnecessary level of detail. 

```{r, echo = FALSE, results = "hide"}
 summary(data_all$education_level)
  
  
  #Make the bar graph of frequencies  
  p2 <- ggplot(data=data_all, aes(fct_infreq(factor(education_level)))) +
    geom_bar(color = "black", fill = "lightgoldenrod1", alpha=.9) +
    theme_clean()+
    labs(x = "", y = "Count") +
    ggtitle("Educational Attainment") + 
    scale_y_continuous(labels = function(x) format(x, big.mark = ",",
                                                   scientific = FALSE))+
    scale_x_discrete(labels = function(x) str_wrap(x, width = 5))

```

```{r fig.width=10, fig.height=4, fig.align="left", echo = FALSE}
p2
```

Distinguishing between people who completed 7th-8th grade, versus 10th, versus 12th grade, and so on, would create additional degrees of freedom that are unlikely to add value to our predictive model. We therefore recode the variable so that all levels below _High School Graduate_ are combined into a single class which we call _12th and below_. 

```{r, message = FALSE, results = "hide"}
data_all$education_level <- combineLevels(data_all$education_level, c('Preschool', '1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'), newLabel = "12th and below")
```
```{r}
levels(data_all$education_level)
```

The resulting summary shows that high school graduates are the most common type of worker (32.7%), followed by people who completed some college (21.9%) and those who obtained a Bachelor's degree. We also see that the smallest proportion of people making less than 50K/year is found among those with educational attainment of 12th grade and below, while the highest proportion (75.4%) is found among those with professional degrees beyond a Bachelor's degree (_Prof-school_). 

```{r, echo=FALSE} 
 proportion3 <- data_all %>%
    group_by(education_level) %>%
    tally() %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p3 <- proportion3 %>% 
    ggplot(aes(x = reorder(education_level, -pct), y = pct)) +
    geom_bar(stat = "identity", position = "dodge", fill = "lightgoldenrod1", color = "black", alpha=.9) +
    geom_text(aes(label = y_label), position = position_dodge(width=.9), vjust = -.25) +
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    xlab("")+
    ylab("")+
    theme_clean()+
    ggtitle("Educational Attainment") 

  
  #Make stacked bars
  proportion4 <- data_all %>%
    group_by(education_level, income_category) %>%
    tally() %>%
    group_by(education_level) %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p4 <- proportion4 %>% 
    ggplot(aes(y = pct, x = education_level, fill = income_category))+
    geom_bar(position = "fill", stat = "identity", alpha = .75) +
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    geom_text(aes(label = y_label), position = position_stack(vjust = .5), color = "black") +
    xlab("")+
    ylab("")+
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    ggtitle("Breakdown of Income Class by Education Attainment") + 
    theme_clean()
  
```


```{r fig.width=10, fig.height=8, fig.align="left", echo = FALSE}
grid.arrange(p3,p4, nrow=2)
```

Next, we examine the __marital_status__ variable. We find that civilian married individuals make up the greatest proportion of the data (46.6%), and that these same people are more likely to be earning more than 50K/year (45.4%). 

```{r, echo=FALSE, results = "hide"} 
 summary(data_all$marital_status)
  
  #Make bar chart
  proportion5 <- data_all %>%
    group_by(marital_status) %>%
    tally() %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p5 <- proportion5 %>% 
    ggplot(aes(x = reorder(marital_status, -pct), y = pct)) +
    geom_bar(stat = "identity", position = "dodge", fill = "lightgoldenrod1", color = "black", alpha=.9) +
    geom_text(aes(label = y_label), position = position_dodge(width=.9), vjust = -.25) +
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    xlab("")+
    ylab("")+
    theme_clean()+
    ggtitle("Marital Status") 
  
  
  #Make stacked bars
  proportion6 <- data_all %>%
    group_by(marital_status, income_category) %>%
    tally() %>%
    group_by(marital_status) %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p6 <- proportion6 %>% 
    ggplot(aes(y = pct, x = marital_status, fill = income_category))+
    geom_bar(position = "fill", stat = "identity", alpha = .75) +
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    geom_text(aes(label = y_label), position = position_stack(vjust = .5), color = "black") +
    xlab("")+
    ylab("")+
    ggtitle("Breakdown of Income Class by Marital Status") + 
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    scale_x_discrete(labels = function(x) str_wrap(x, width = 5))+
    theme_clean()
  
```

```{r fig.width=10, fig.height=8, fig.align="left", echo = FALSE}
grid.arrange(p5,p6, nrow=2)
```

Looking at the __occupation__ variable, we note that occupations are fairly evenly distributed in the sample, and that, unsurprisingly, individuals in managerial roles (_Exec-managerial_) and those with a white-collar specialty (_Prof-specialty_) are most likely to make above 50K/year, with 47.9% and 45% of respondents in that income category respectively. 


```{r, echo=FALSE, results = "hide"} 
summary(data_all$occupation)
  
  #Make bar chart
  proportion7 <- data_all %>%
    group_by(occupation) %>%
    tally() %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p7 <- proportion7 %>% 
    ggplot(aes(x = reorder(occupation, -pct), y = pct)) +
    geom_bar(stat = "identity", position = "dodge", fill = "lightgoldenrod1", color = "black", alpha=.9) +
    geom_text(aes(label = y_label), position = position_dodge(width=.9), vjust = -.25) +
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    xlab("")+
    ylab("")+
    scale_x_discrete(labels = function(x) str_wrap(x, width = 5))+
    theme_clean()+
    ggtitle("Type of Occupation") 
  
  
  #Make stacked bars
  proportion8 <- data_all %>%
    group_by(occupation, income_category) %>%
    tally() %>%
    group_by(occupation) %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p8 <- proportion8 %>% 
    ggplot(aes(y = pct, x = occupation, fill = income_category))+
    geom_bar(position = "fill", stat = "identity", alpha = .75) +
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    geom_text(aes(label = y_label), position = position_stack(vjust = .5), color = "black") +
    xlab("")+
    ylab("")+
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    scale_x_discrete(labels = function(x) str_wrap(x, width = 4)) +
    ggtitle("Breakdown of Income Class by Type of Occupation") + 
    theme_clean()
```

```{r fig.width=10, fig.height=4, fig.align="left", echo = FALSE}
  plot_grid(p7)
```

```{r fig.width=14, fig.height=8, fig.align="left", echo = FALSE}
  plot_grid(p8)
```

The __sex__ variable reveals that the majority of survey responders (67.5%) are male, and that men are more likely than women to earn more than 50K/year (32.1% versus 11.4%).

```{r, echo=FALSE, results = "hide"} 
summary(data_all$sex)
    
    #Make bar chart
    proportion9 <- data_all %>%
      group_by(sex) %>%
      tally() %>%
      mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
    
    
    p9 <- proportion9 %>% 
      ggplot(aes(x = reorder(sex, -pct), y = pct)) +
      geom_bar(stat = "identity", position = "dodge", fill = "lightgoldenrod1", color = "black", alpha=.9) +
      geom_text(aes(label = y_label), position = position_dodge(width=.9), vjust = -.25) +
      scale_y_continuous(labels = percent_format(accuracy = 1))+
      xlab("")+
      ylab("")+
      theme_clean()+
      ggtitle("Sex") 
    
    #Make stacked bars
    proportion10 <- data_all %>%
      group_by(sex, income_category) %>%
      tally() %>%
      group_by(sex) %>%
      mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
    
    
    p10 <- proportion10%>% 
      ggplot(aes(y = pct, x = sex, fill = income_category))+
      geom_bar(position = "fill", stat = "identity", alpha = .75) +
      scale_fill_viridis(discrete=TRUE, option = "viridis")+
      geom_text(aes(label = y_label), position = position_stack(vjust = .5), color = "black") +
      xlab("")+
      ylab("")+
      ggtitle("Breakdown of Income Class by Sex") + 
      scale_y_continuous(labels = percent_format(accuracy = 1))+
      theme_clean()
```

```{r fig.width=10, fig.height=6, fig.align="left", echo = FALSE}
grid.arrange(p9,p10, nrow=1)  
```

We skip over the __relationship__ variable because the metadata does not provide enough information on what it means. While census bureau documentation explains that the __relationship__ question denotes each household member's relationship to the primary householder (the person who owns or rents the housing unit), the variable in our dataset does not contain a class which is the equivalent of "self". The levels and their frequencies are as follows:

```{r, echo=FALSE}
summary(data_all$relationship) 
```

The absence of a class equivalent to "self" suggests that the UCI sample excludes primary householders altogether, yet the fact that most survey respondents are male (67.5%) and "husband" is the most common class of the __relationship__ variable suggests otherwise. Another possibility is that __relationship__ actually denotes the role of the individual in the household. This would explain the high prevalence of males and "husband" as the relationship type; however we do not have enough information to ascertain our hypothesis. 

We move on to examine variability along the __race__ variable, and note that an overwhelming majority (86%) of the survey respondents are white, and that the rate of people earning more than 50K/year is highest among the Asian/Pacific Islander ethnic group (28.3%), followed by caucassians at 26.2%.  

```{r, echo=FALSE, results = "hide"} 
summary(data_all$race)
  
  #Make bar chart
  proportion11 <- data_all %>%
    group_by(race) %>%
    tally() %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p11 <- proportion11 %>% 
    ggplot(aes(x = reorder(race, -pct), y = pct)) +
    geom_bar(stat = "identity", position = "dodge", fill = "lightgoldenrod1", color = "black", alpha=.9) +
    geom_text(aes(label = y_label), position = position_dodge(width=.9), vjust = -.25) +
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    xlab("")+
    ylab("")+
    theme_clean()+
    scale_x_discrete(labels = function(x) str_wrap(x, width = 5))+
    ggtitle("Race/Ethnic Origin") 
  
  
  #Make stacked bars
  proportion12 <- data_all %>%
    group_by(race, income_category) %>%
    tally() %>%
    group_by(race) %>%
    mutate(pct = n / sum(n), y_label = paste0(round(pct*100, 1), "%"))
  
  
  p12 <- proportion12 %>% 
    ggplot(aes(y = pct, x = race, fill = income_category))+
    geom_bar(position = "fill", stat = "identity", alpha = .75) +
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    geom_text(aes(label = y_label), position = position_stack(vjust = .5), color = "black") +
    xlab("")+
    ylab("")+
    ggtitle("Breakdown of Income Class by Race") + 
    scale_y_continuous(labels = percent_format(accuracy = 1))+
    scale_x_discrete(labels = function(x) str_wrap(x, width = 5))+
    theme_clean()
```

```{r fig.width=10, fig.height=6, fig.align="left", echo = FALSE}
grid.arrange(p11,p12, nrow=1)  
```

Finally, we examine the structure of the __native_country__ variable. A summary of this categorical feature shows that it contains 41 different levels, most of which have very few observations. 

```{r, echo=FALSE}
levels(data_all$native_country)
```

Because keeping so many levels as an input is likely to add unnecessary degrees of freedom and bring down our model's performance, we collapse countries of origin into regional categories. We assign these categories to a new variable, __native_region__:

```{r}

Asia <- c("Cambodia", "India", "Laos", "Thailand", "Vietnam", "Hong", "Iran", "China", "Japan", "Philippines", "Taiwan")
      
    Europe <- c("France", "Italy", "Poland", "Scotland", "Germany", "Portugal", "Yugoslavia", "England", "Greece", "Holand-Netherlands", "Hungary", "Ireland")
    
    North_America <- c("Outlying-US(Guam-USVI-etc)", "Canada", "United-States", "Puerto-Rico")
    
    Latin_America_Carrib <- c("Columbia", "Ecuador", "Guatemala", "Honduras", "Cuba", "El-Salvador", "Haiti", "Jamaica", "Mexico", "Peru", "Trinadad&Tobago", "Dominican-Republic", "Nicaragua")
    
    Unknown <- c("South")
    
    data_all <- data_all %>% mutate(native_region = case_when(native_country %in% Asia ~ "Asia",
                                   native_country %in% Europe ~ "Europe", 
                                   native_country %in% North_America ~ "North_America",
                                   native_country %in% Latin_America_Carrib ~ "Latin_America_Carrib",
                                   native_country %in% Unknown ~ "Unknown"))

```

Our __native_region__ feature will replace the __native_country__ variable. It has the following values:

```{r, echo = FALSE}

data_all$native_region <- as.factor(data_all$native_region)
    
levels(data_all$native_region)

```
Here, "Unknown" corresponds to the entries with the ambiguous value of "South".

#### __II.2 Continuous Attributes__

We move on to examine the distribution of values along our continuous predictors. We see that 50% of survey respondents are between the ages of 28 and 47, and and that the age variable has a right-skewed distribution, as there is a higher concentration of individuals below the median age than above it. This what we would expect from sampling a population of working-age individuals. We also see from looking at boxplots and density plots of age along our two income categories that the age distribution of people earning more than 50K/year is older and and has less variability than that of people earning below that threshold. 

```{r, echo = FALSE}
  
  summary(data_all$age)
  
  #Make the histogram
  p13 <- data_all %>% ggplot(aes(age)) +
    geom_histogram(binwidth = 1, color = "black", fill = "purple4", alpha=.95) +
    theme_clean()+
    labs(x = "", y = "Count") +
    ggtitle("Age Distribution") 
  
  
  #Make box plots
  p14 <- data_all %>% ggplot(aes(income_category, age, fill = income_category)) +
    geom_boxplot(alpha = .8) +
    xlab("")+
    ylab("Age")+
    ggtitle("Age by Income Category")+
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    theme_clean() 
    
  #Make density plot
  p15 <- data_all %>% ggplot(aes(x = age, fill = income_category)) +
    geom_density(position = "identity", alpha = .6) +
    ggtitle("Age Density by Income Category")+
    scale_fill_viridis(discrete=TRUE, option = "viridis")+
    xlab("")+
    ylab("Density")+
    theme_clean()
```

```{r fig.width=10, fig.height=6, fig.align="left", echo = FALSE}
grid.arrange(p13,p14,nrow=1)  
```

```{r fig.width=10, fig.height=4, fig.align="left", echo = FALSE}
grid.arrange(p15)  
```

Finally, we examine the distribution of values contained in the __capital_loss__ and the __capital_gain__ variables. Density plots of these attributes suggest that the values are heavily skewed towards zero.

```{r, echo = FALSE, results = "hide"}
  summary(data_all$capital_loss)
  summary(data_all$capital_gain)
  
  p16 <- data_all %>% ggplot(aes(x = capital_loss)) +
    geom_density(fill = "purple4", alpha=.95) +
    theme_clean()+
    labs(x = "", y = "Density") +
    ggtitle("Distribution of Capital Loss") 
  
  
  p17 <- data_all %>% ggplot(aes(x = capital_gain)) +
    geom_density(fill = "gold", alpha=.95) +
    theme_clean()+
    labs(x = "", y = "Density") +
    ggtitle("Distribution of Capital Gain") 
```  
 
```{r fig.width=10, fig.height=4, fig.align="left", echo = FALSE}
grid.arrange(p16,p17,nrow=1)  
```

We perform a summary computation to ascertain this and see that there are indeed very few instances of values that differ from zero. 91.6% of the survey respondents have no capital gain, and and 95.3% have no capital loss. 

```{r}
data_all %>% filter(capital_gain == 0) %>% summarise(value = 0, prevalence = n()/45222*100)
    data_all %>% filter(capital_loss == 0) %>% summarise(value = 0, prevalence = n()/45222*100)
```  

Such a high prevalence of zeros in a continuous variable is likely to distort our predictions. We must therefore create bins so that we can treat both __capital_gain__ and __capital_loss__ as categorical features in our predictive model. In order to compute these bins, we first explore the distribution of the non-zero values for each variable. We compute the quantiles and get the below results:


```{r, echo = FALSE}
q_gain <- quantile(x = subset(data_all$capital_gain, data_all$capital_gain != 0), probs = seq(0, 1, .25))
q_loss <- quantile(x = subset(data_all$capital_loss, data_all$capital_loss != 0), probs = seq(0, 1, .25))
    
quantiles <- data.frame(Capital_Gain = q_gain, Capital_Loss = q_loss)

quantiles %>% kable(caption = "Non-Zero Capital Gain and Capital Loss Quantiles") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```  

We note that the interquartile range for __capital_gain__ (10,620) is significantly larger than the IQR for __capital_loss__ (305). Then, we create histograms and boxplots of the non-zeros values of __capital_gain__ and __capital_loss__ to further investigate the distribution of these attributes before creating cutoff values for our bins. 


```{r, echo = FALSE}

 pos_gain <- subset(data_all, capital_gain != 0)
 neg_loss <- subset(data_all, capital_loss != 0)
    
p18 <- pos_gain %>% ggplot(aes(capital_gain)) +
      geom_histogram(binwidth = 2500, color = "black", fill = "gold", alpha=.95) +
      theme_clean()+
      labs(x = "", y = "Count") +
      scale_x_continuous(labels = comma) +
      scale_y_continuous(breaks = seq(0,1000,50)) +
      ggtitle("Histogram of Non-Zero Capital Gain") 
    
    p19 <- neg_loss %>% ggplot(aes(capital_loss)) +
      geom_histogram(binwidth = 200, color = "black", fill = "purple4", alpha=.95) +
      theme_clean()+
      labs(x = "", y = "Count") +
      scale_x_continuous(labels = comma) +
      scale_y_continuous(breaks = seq(0,1000,50)) +
      ggtitle("Histogram of Non-Zero Capital Loss") 
```

```{r fig.width=10, fig.height=4, fig.align="center", echo = FALSE}
grid.arrange(p18,p19,nrow=1)  
```

```{r, echo = FALSE}
p20 <- pos_gain %>% ggplot(aes(x = factor(0), y = capital_gain)) +
     geom_boxplot(alpha = .8, fill = "gold") +
     xlab("")+
     ylab("Capital Gain")+
     ggtitle("Boxplot of Non-Zero Capital Gain") +
     scale_y_continuous(breaks = seq(0, 100000, 5000)) +
     stat_summary(fun.y = mean, 
                  geom = 'point', 
                  shape = 19,
                  color = "red",
                  cex = 2) +
     scale_fill_viridis()+
     theme_clean()  
   
   p21 <- neg_loss %>% ggplot(aes(x = factor(0), y = capital_loss)) +
     geom_boxplot(alpha = .8, fill = "darkorchid4") +
     xlab("")+
     ylab("Capital Loss") +
     scale_y_continuous(breaks = seq(0, 5000, 500)) +
     stat_summary(fun.y = mean, 
                  geom = 'point', 
                  shape = 19,
                  color = "red",
                  cex = 2) + 
     ggtitle("Boxplot of Non-Zero Capital Loss") +
     theme_clean()  
```

```{r fig.width=10, fig.height=4, fig.align="center", echo = FALSE}
grid.arrange(p20,p21,nrow=1)  
```

We see that the distribution of non-zero values of __capital_gain__ is left-skewed, with most pepple having a capital gain between $2,500 and $27,500 - the most common value being $7,500 - and that there is a handful of outliers with a capital gain of $100,000. The distribution for __capital_loss__ on the other hand, is more symmetric, with most values falling between $1,400 and $2,400 - the most common value being $2,000 - and a large number of outliers above and below this window.

We then create the following levels for __capital_gain__ as a factor variable:

* Values equal to or below the first quartile of non-zero values ($3,464): Low
  
* Values between the first and third quartile of non-zero values ($3,464 to $14,084): Medium
  
* Values above the third quartile of non-zero values ($14,084): High

We do the same for __capital_loss__ and create the following levels:

* Values equal to or below the first quartile of non-zero values ($1,672): Low
  
* Values between the first and third quartile of non-zero values ($1,672 to $1,977): Medium

* Values above the third quartile of non-zero values ($1,977): High

The code looks like this:

```{r}
data_all <- data_all %>% 
      mutate(cap_gain = ifelse(capital_gain <= 3464, " Low",
                               ifelse(capital_gain > 3464 & capital_gain < 14084, " Medium", " High")))
    
    
    data_all$cap_gain <- factor(data_all$cap_gain,
                                ordered = TRUE,
                                levels = c(" Low", " Medium", " High"))
    
    data_all <- data_all %>% 
      mutate(cap_loss = ifelse(capital_loss <= 1672, " Low",
                               ifelse(capital_gain > 1672 & capital_gain < 1977, " Medium", " High")))
    
    
    data_all$cap_loss <- factor(data_all$cap_loss,
                                ordered = TRUE,
                                levels = c(" Low", " Medium", " High"))
    
```

After making these modifications to our features, we proceed to conduct a correlation analysis in order to assess how interrelated they are. This is important because in order to build an efficient predictive model, it is best to only include variables that __uniquely__ explain some amount of variance in the outcome. Because correlations are most easily computed on numeric variables, we convert all the values of our categorical variables to numeric levels after subsetting our data to exclude the outcome variable (__income_category__) and the demographic __weight__ variable. Simple integer encoding is not enough however, since our categorical variables are nominal and have a multiplicity of levels (some are binary while others have many levels). We therefore one-hot encode all the categorical variables so each only has two values: _Yes (1) or No (0)_. 
